<h1>64-bit vs 32-bit</h1>

As 64-bit machines become more common, the problems we need to solve also evolve. 
In this post I’d like to talk about what it means for the GC and the applications’ memory usage when we move from 32-bit to 64-bit.

 

One big limitation of 32-bit is the virtual memory address space – as a user mode process you get 2GB, 
and if you use large address aware you get 3GB. 
A few years these seemed like giant numbers but I’ve seen as more and more people start using .NET framework, 
the sizes of the managed heap go up at a quite high rate. 
I remember when I first started working on GC (which was late 2004 I think) 
we were talking about hundreds of MBs of heaps – 300MB seemed like a lot. Today I am seeing managed heaps easily of GBs in size – and yes, 
some of them (and more and more of them) are on 64-bit – 2 or 3GB is just not enough anymore.

 

And along with this, we are shifting to solving a different set of problems. 
In CLR 2.0 we concentrated heavily on using the VM space efficiently. 
We tried very hard to reduce the fragmentation on the managed heap so when you get a hold of a chunk of virtual memory you can make very efficient use of it. 
So people don’t see problems like they have N managed heap segments, are running out of VM, yet many of these segments are quite empty (meaning having a lot of free space on them).

 

Then you switch to 64-bit. Now suddenly you don’t need to worry about VM anymore – you get plenty there. 
Practically unlimited for many applications (of course it’s still limited – for example if you are running out physical memory to even allocate the datastructures for virtual pages then you still can’t reserve those pages). What kind of differences will you see in your managed memory usage?

 

First of all, your process consumes more memory – I am sure all of you are already aware of this – the pointer size is bigger – it’s doubled on 64-bit so
 if you don’t change anything at all, now your managed heap (which undoubtly contains references) is bigger. 
Of course being able to manipulate memory in QWORDs instead of DWORDs can also be beneficial –our measurements show that the raw allocation speed is slightly higher on 64-bit than on 32-bit that can be attributed to this.

 

There are other factors that could make your process consume more memory – for example the module size is bigger (mscorwks.dll is about 5MB on x86, 10MB on x64 and 20MB on ia64), 
instructions are bigger on 64-bit and what have you.

 

Another thing you may notice – if you have looked at the performance counters under .NET CLR Memory – is that you are now doing a lot fewer GCs on 64-bit than what you used to see on 32-bit.

 

The curious minds might have already noticed one thing – the managed heap segments are much bigger in size on 64-bit. If you do !SOS.eeheap -gc you will now see way bigger segments.

 

Why did we make the segment size so much bigger on 64-bit? Well, 
remember we talked about in Using GC Efficiently Part 2 how we have a budget for gen0 and when you’ve allocated more than this budget a GC will be triggered. 
When you have a bigger budget it means you’ll need to do fewer GCs which means your code will get more chance to run.
 From this perspective you should get a performance gain when you move to 64-bit – I want to emphasize the “this perspective” part because in general things tend to run slower on 64-bit. 
 The perf benefit you get because of GC may very well be obscured by other perf degrades. 
 In reality many people are not expecting perf gain when they move to 64-bit but rather they are happy with being able to use more memory to handle more work load.

 

Of course we also don’t want to wait for too long before we collect – we strive for the right balance between memory (how much memory your app consumes) and CPU (how often user threads run).

https://devblogs.microsoft.com/dotnet/64-bit-vs-32-bit/

随着64位机器变得越来越普遍，我们需要解决的问题也在不断演变。在这篇文章中，我想讨论一下当我们从32位迁移到64位时，对垃圾回收器（GC）和应用程序内存使用的影响。

32位的限制
32位机器的一个主要限制是虚拟内存地址空间——用户模式进程只能获得2GB的虚拟内存空间，如果使用“大地址感知”（large address aware），则可以获得3GB。几年前，这些数字看起来非常大，
但随着越来越多的人开始使用.NET框架，托管堆的大小以相当高的速度增长。我记得当我刚开始研究GC时（大概是2004年底），我们讨论的是几百MB的堆——300MB似乎已经很多了。
而今天，我看到托管堆的大小轻松达到GB级别——是的，其中一些（而且越来越多）是在64位机器上运行的——2GB或3GB已经不够用了。

从32位到64位的转变
随着这种变化，我们正在转向解决一组不同的问题。在CLR 2.0中，我们专注于高效使用虚拟内存空间。我们非常努力地减少托管堆上的碎片，以便在获得一块虚拟内存时能够非常高效地使用它。
这样，用户就不会遇到诸如“有N个托管堆段，虚拟内存不足，但其中许多段实际上很空（即有很多空闲空间）”的问题。

然后，当你切换到64位时，突然之间你不再需要担心虚拟内存了——你拥有大量的虚拟内存。对于许多应用程序来说，这几乎是无限的（当然，它仍然是有限的——例如，如果你连虚拟页面的数据结构都无法分配物理内存，
那么你仍然无法保留这些页面）。在托管内存使用方面，你会看到哪些不同呢？

64位下的内存消耗
首先，你的进程会消耗更多的内存——我相信你们都已经意识到了这一点——指针的大小变大了，在64位下翻倍了。因此，如果你不做任何改变，你的托管堆（毫无疑问包含引用）会变得更大。
当然，能够以QWORD（64位）而不是DWORD（32位）操作内存也可能带来好处——我们的测量显示，64位下的原始分配速度略高于32位，这可能归因于此。

还有其他因素可能导致你的进程消耗更多内存——例如，模块的大小变大了（mscorwks.dll在x86上约为5MB，在x64上约为10MB，在ia64上约为20MB），64位下的指令也更大，等等。

GC频率的变化
你可能会注意到的另一件事是——如果你查看过“.NET CLR Memory”下的性能计数器——在64位下，你进行的GC次数比在32位下少得多。

好奇的人可能已经注意到一件事——64位下的托管堆段要大得多。如果你运行!SOS.eeheap -gc，你会看到更大的段。

为什么64位下的段大小更大？
为什么我们在64位下将段大小设置得这么大？还记得我们在《高效使用GC第2部分》中讨论过，我们为gen0设置了一个预算，当你分配的超过这个预算时，就会触发GC。当你有一个更大的预算时，
意味着你需要进行的GC次数更少，这意味着你的代码有更多的机会运行。从这个角度来看，当你迁移到64位时，你应该获得性能提升——我想强调“从这个角度来看”这一部分，因为通常情况下，64位下的运行速度会变慢。
由于GC带来的性能提升可能很容易被其他性能下降所掩盖。实际上，许多人在迁移到64位时并不期望获得性能提升，而是更高兴能够使用更多的内存来处理更大的工作负载。

当然，我们也不希望等待太久才进行回收——我们努力在内存（你的应用程序消耗多少内存）和CPU（用户线程运行的频率）之间找到正确的平衡。

总结
从32位迁移到64位带来了虚拟内存空间的巨大扩展，这使得应用程序能够处理更大的工作负载。然而，这也带来了更高的内存消耗和不同的性能特征。64位下的托管堆段更大，GC频率更低，这在一定程度上提升了性能，
但也需要权衡内存和CPU的使用效率。