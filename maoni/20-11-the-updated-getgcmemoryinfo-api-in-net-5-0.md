<h1>The updated GetGCMemoryInfo API in .NET 5.0 and how it can help you</h1>

A bit of history
In .NET 3.0 we introduced a GC.GetGCMemoryInfo API for library code to get memory load related things (this was used in ArrayPool for example) so it exposed things library folks wanted at the time. In 5.0 I got requests from folks to monitor more things about the GC. Instead of adding a bit of info each time someone asks, I really thought about the kinds of things that would help with monitoring and diagnostics and expanded the info provided by this API significantly. It also has a new overload, documented here. The returned GCMemoryInfo struct has many more properties.

Goals of the updated API
You can view the new GetGCMemoryInfo API as a rich sampling method. Many people enjoyed using perf counters in the old days. The problem with perf counters was

The info was pretty primitive
It's hard to correlate the info for the same GC since you get counters individually.
2) is less of a problem just because most of the time folks didn't care about individual GCs, they just cared about a trend. And counters were really just used for monitoring, not for diagnostics 'cause they simply didn't provide enough info to look at the GCs in any kind of depth. I wanted the new API to be used for both. There was quite a bit of discussion on the API proposal and with help from other people on my team I think I landed at an API that I'm quite happy about. Big kudos to Noah for suggesting to take the kind of GC as a parameter which makes it still very useful for understanding what's going on even when you are monitoring with very long intervals which was a big problem with perf counters â€“ you get whatever values the last GC happened to set which meant if you only sample once in a long time (like once every minute), it's based on luck whether you catch a long GC pause 'cause that GC could easily not be the last GC that interval caught. By specifying the GC kind if you do sample only once in a long time, you could always get the last full blocking GC (GCKind.FullBlocking) which has the longest GC pause because you can specific ask about that kind of GCs.

Some implementation detail
Since I know many people who read my blog are curious about implementation details I wanted to mention some about this API implementation. You might think this should be very straightforward to implement but as with most things in GC it's rarely straightforward ğŸ˜…. When you call the API, you get back an instance of the GCMemoryInfo type and all fields of this instance are for the last completed GC, or the last completed GC of the GCKind you specify. It's never the case that some values in this instance belong to a GC and others belong to a different GC. And this is easy to get when we do a blocking GC because user code is not running at the same time. At the end of that blocking GC we fill in all fields for that GC and then resume user code so it's easily guaranteed that all fields are for the same GC. But it's more complicated, as usual, for a background GC. What I did was to maintain an array of 2 element of BGC info and when a BGC starts, it flips the index to !index. This is done while the user threads are suspended so there's no synchronization issues. And this is the index the BGC will log its info to. If the user code calls the API asking for the last BGC while a BGC is in progress, it returns the other index which we know is for the last completed BGC (or all 0s, if the current BGC is the very first BGC that's happening). And if no BGC is in progress, it returns what the index points to because we know that means that BGC was complete and is the last BGC.

Another somewhat tricky thing about this API was the interaction between BCL and the runtime (I know that now BCL is also in the runtime repo; I'm still used to using runtime to refer to just the native part which is what's in coreclr.dll). I mostly work only with native code in the runtime and rarely step onto the BCL side since GC has such a small public surface area. And usually the BCL part of a GC API is pretty straightforward but this API was an exception. If you look at the calls that the BCL makes into the runtime, they usually take very simple arguments which means they are easy to pass back and forth between managed and native code. This API was not like that â€“ it passes a fairly complicated structure which has both array fields and non array fields. At first I was doing some complicated things on the native side to fill in the arrays because I'm pretty inept with the managed side of things and I was not happy about that. So I enlisted Jan's help and he found a much more elegant way of doing what I wanted to do which I went with. The implementation of this was split between GCMemoryInfo.cs, GC.cs on the managed side and comutilnative.cpp on the native side. I would imagine very, very few people ever need to do this but if you ever do, this would serve as a very good example.

Most of the properties in the GCMemoryInfo struct are pretty self explanatory. The only one that might cause confusion is the Index. Before any GCs happen, if you call the API it will get back 0 for Index. The first GC's index will be 1, 2nd one will be 2 and so on. You can also correlate this number with what you get back at GC.CollectionCount which is cheaper since we just get back a number whereas GetGCMemoryInfo needs to fill out many fields. If the first GC is a gen0 GC, GC.CollectionCount(0) would return 1, which is the same as GCMemoryInfo.Index you get back when you call GetGCMemoryInfo() or GetGCMemoryInfo(GCKind.Ephemeral). Of course since we are doing all in managed code, it means a GC can happen between your calling CollectionCount and GetGCMemoryInfo because other threads could have triggered a GC or you are under memory pressure but the chance of that actually happening is quite small. Note that an attribute of CollectionCount is when we increase a higher generation's collection count, all its lower generations' counts are also increased. So if a gen1 GC happened at the very beginning, CollectionCount(0) and CollectionCount(1) would both return 1.

What can you use the info for?
The returned GCMemoryInfo provides a wealth of info about that GC such as the generation, whether it was compacting or not, whether it was concurrent or not, how many pinned objects that GC observed, pause duration(s) and etc. Basically you could think of this as the combination of the detailed info you get from GC ETW events. Since folks have a variety of ways to do monitoring and diagnostics this just made it easier if you do in-proc monitoring and want to get GC info (eg, if you already have a thread that does monitoring you can totally beef it up by calling this API for memory monitoring). I can easily think of many things to do with the info, below are just some examples â€“

1) I can't tell you how many times people have asked "the GC heap size is X, but my process's usage is a lot higher than that! Why is this?". It turned out that they were simply not measuring the peak size. They were either measuring the size right after a GC (which would be the smallest size) or a size at a random point (which could be fresh out of a GC and very close to the smallest size). This is explained the How to look at the GC heap size properly section of mem-doc. ETW, being the richest info we provide, of course gives you this data but I have seen folks misinterpreting what the ETW event tells them. Recently I had a customer who told me that they didn't think hardlimit they specified was working because the GC heap remained very small even after they increase the hardlimit. This was because they were looking at fields of the GCHeapStats event which reports the "right after a GC" value. Granted, we could do a better job at documenting these events. But I think the GetGCMemoryInfo API makes it very explicit what you are getting â€“ GCGenerationInfo explicitly says SizeBeforeBytes which is the size on entry of a GC which denotes the peak size â€“


public readonly struct GCGenerationInfo
{
    /// <summary>Size in bytes on entry to the reported collection.</summary>
    public long SizeBeforeBytes{ get; }
    
    /// <summary>Fragmentation in bytes on entry to the reported collection.</summary>
    public long FragmentationBeforeBytes{ get; }
    
    /// <summary>Size in bytes on exit from the reported collection.</summary>
    public long SizeAfterBytes{ get; }
    
    /// <summary>Fragmentation in bytes on exit from the reported collection.</summary>
    public long FragmentationAfterBytes{ get; }
}
view rawGenInfo.cs hosted with â¤ by GitHub
The same info is provided as part of the GCPerHeapHistoryGenData in TraceEvent but in more detail â€“ we separate the fragmentation into FreeListSpace and FreeObjSpace â€“ the latter is for free objects that are too small to get on the free list.

2) Another question I get frequently is "I see there's all this free space in GC, why isn't GC using it?". Again, this is very much affected by when you measure. If you measure right after a BGC, since its job is to build up free space you'd likely see a ton of free space in gen2/LOH. So with the API you get the fragmentation (which is the total amount of free space) before and after a GC so you know if GC is using the free space or not. For example if you have a lot of long lived pins that are scattered in gen0 (since we demoted them), the FragmentationAfterBytes could be quite big 'cause there's a lot of free space in-between the pins. But you should see FragmentationBeforeBytesto be much smaller as we'd have used the free space to satisfy your allocation requests.

3) You could monitor quite infrequently by calling this API with GCKind.FullBlocking which tells you if a full blocking GC has happened if you want to make they don't happen since Full blocking GCs could introduce very long pauses.


4) The "% time in GC" perf counter was only for the last GC (and not accurate if a BGC happened). For long term monitoring, it's more useful to know what the % Pause time in GC is so far. So the PauseTimePercentage provided by the API is exactly that so it's very suitable for long term monitoring. And if you want to know individual GC's pause duration, you can always look at the PauseDurations property which provides 2 durations â€“ only the first one is used for blocking GCs since they only have one GC pause. For BGCs there are 2 durations since each BGC will pause twice â€“ one is the initial pause and the 2nd one is at the end of the mark phase (described in the GC event sequence section in mem-doc). And you can get each of these pause durations. This is actually more detailed than what TraceEvent provides which combines these 2 pauses into 1 and reports that and you see this in the Pause MSec column in the GCStats view in PerfView.

5) I talked about just how important it is to be aware of the generational aspect of the GC in mem-doc. Unfortunately so few tools actually expose this generational aspect. Even some seasoned perf engineers are not aware of it at all. This API provides the PromotedBytes for each GC and you can clearly see the promoted bytes for ephemeral GCs vs full GCs. For example, you can correlate the PauseDurations[0] of ephemeral GCs with their PromotedBytes. And if you see that they totally don't correlate, eg, the pause durations vary greatly even though the promoted remained stable, you might be hitting the stolen CPU problem if you are using Server GC.

### ä¸€ç‚¹å†å²èƒŒæ™¯

åœ¨ .NET 3.0 ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸º `GC.GetGCMemoryInfo` çš„ APIï¼Œç”¨äºåº“ä»£ç è·å–ä¸å†…å­˜è´Ÿè½½ç›¸å…³çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œè¿™ä¸ª API åœ¨ ArrayPool ä¸­è¢«ä½¿ç”¨ï¼‰ï¼Œå› æ­¤å®ƒæš´éœ²äº†ä¸€äº›å½“æ—¶åº“å¼€å‘è€…å¸Œæœ›è·å–çš„å†…å®¹ã€‚åˆ°äº† .NET 5.0ï¼Œæˆ‘æ”¶åˆ°äº†æ¥è‡ªè®¸å¤šå¼€å‘è€…çš„è¯·æ±‚ï¼Œå¸Œæœ›ç›‘æ§æ›´å¤šå…³äº GC çš„ä¿¡æ¯ã€‚ä¸å…¶æ¯æ¬¡æœ‰äººæå‡ºéœ€æ±‚å°±æ·»åŠ ä¸€äº›ä¿¡æ¯ï¼Œæˆ‘æ›´æ·±å…¥åœ°æ€è€ƒäº†å“ªäº›å†…å®¹æœ‰åŠ©äºç›‘æ§å’Œè¯Šæ–­ï¼Œå¹¶æ˜¾è‘—æ‰©å±•äº†è¯¥ API æä¾›çš„ä¿¡æ¯ã€‚å®ƒè¿˜æ–°å¢äº†ä¸€ä¸ªé‡è½½æ–¹æ³•ï¼Œå…·ä½“æ–‡æ¡£å¯ä»¥å‚è€ƒè¿™é‡Œã€‚è¿”å›çš„ `GCMemoryInfo` ç»“æ„ä½“åŒ…å«äº†è®¸å¤šæ–°çš„å±æ€§ã€‚

### æ›´æ–° API çš„ç›®æ ‡

ä½ å¯ä»¥å°†æ–°çš„ `GetGCMemoryInfo` API è§†ä¸ºä¸€ç§ä¸°å¯Œçš„é‡‡æ ·æ–¹æ³•ã€‚è¿‡å»å¾ˆå¤šäººå–œæ¬¢ä½¿ç”¨æ€§èƒ½è®¡æ•°å™¨ã€‚ç„¶è€Œï¼Œæ€§èƒ½è®¡æ•°å™¨çš„é—®é¢˜åœ¨äºï¼š

1. **ä¿¡æ¯éå¸¸åŸºç¡€**  
2. **å¾ˆéš¾å°†åŒä¸€ GC çš„ä¿¡æ¯å…³è”èµ·æ¥ï¼Œå› ä¸ºè®¡æ•°å™¨æ˜¯å•ç‹¬è·å–çš„**

ç¬¬ 2 ç‚¹ä¹‹æ‰€ä»¥ä¸æ˜¯å¤§é—®é¢˜ï¼Œæ˜¯å› ä¸ºå¤§å¤šæ•°æ—¶å€™å¼€å‘è€…å¹¶ä¸å…³å¿ƒå•ä¸ª GCï¼Œä»–ä»¬åªå…³å¿ƒè¶‹åŠ¿ã€‚è€Œè®¡æ•°å™¨é€šå¸¸åªç”¨äºç›‘æ§ï¼Œè€Œä¸æ˜¯è¯Šæ–­ï¼Œå› ä¸ºå®ƒä»¬æä¾›çš„ä¿¡æ¯ä¸è¶³ä»¥æ·±å…¥åˆ†æ GCã€‚æˆ‘å¸Œæœ›æ–°çš„ API èƒ½åŒæ—¶æ»¡è¶³ç›‘æ§å’Œè¯Šæ–­çš„éœ€æ±‚ã€‚åœ¨ API ææ¡ˆä¸­è¿›è¡Œäº†å¤§é‡çš„è®¨è®ºï¼Œåœ¨å›¢é˜Ÿå…¶ä»–æˆå‘˜çš„å¸®åŠ©ä¸‹ï¼Œæˆ‘è®¤ä¸ºæœ€ç»ˆè®¾è®¡å‡ºäº†ä¸€ä¸ªä»¤æˆ‘æ»¡æ„çš„ APIã€‚ç‰¹åˆ«æ„Ÿè°¢ Noah å»ºè®®å°† GC ç±»å‹ä½œä¸ºå‚æ•°ä¼ é€’ï¼Œè¿™ä½¿å¾—å³ä½¿åœ¨ä»¥å¾ˆé•¿çš„æ—¶é—´é—´éš”è¿›è¡Œç›‘æ§æ—¶ï¼ŒAPI ä»ç„¶éå¸¸æœ‰ç”¨â€”â€”æ€§èƒ½è®¡æ•°å™¨çš„ä¸€ä¸ªå¤§é—®é¢˜æ˜¯ï¼Œä½ åªèƒ½è·å–æœ€åä¸€ä¸ª GC è®¾ç½®çš„å€¼ï¼Œè¿™æ„å‘³ç€å¦‚æœä½ æ¯éš”å¾ˆé•¿æ—¶é—´é‡‡æ ·ä¸€æ¬¡ï¼ˆä¾‹å¦‚æ¯åˆ†é’Ÿä¸€æ¬¡ï¼‰ï¼Œæ˜¯å¦èƒ½æ•è·åˆ°é•¿æ—¶é—´çš„ GC æš‚åœå®Œå…¨å–å†³äºè¿æ°”ï¼Œå› ä¸ºé‚£ä¸ª GC å¯èƒ½å¹¶ä¸æ˜¯åŒºé—´å†…æœ€åä¸€ä¸ª GCã€‚é€šè¿‡æŒ‡å®š GC ç±»å‹ï¼ˆå¦‚ `GCKind.FullBlocking`ï¼‰ï¼Œå³ä½¿é‡‡æ ·é¢‘ç‡å¾ˆä½ï¼Œä½ ä¹Ÿå¯ä»¥å§‹ç»ˆè·å–æœ€åä¸€ä¸ªå®Œæ•´çš„é˜»å¡ GCï¼Œå› ä¸ºå®ƒå…·æœ‰æœ€é•¿çš„æš‚åœæ—¶é—´ã€‚

---

### å®ç°ç»†èŠ‚

ç”±äºæˆ‘çŸ¥é“å¾ˆå¤šè¯»è€…å¯¹å®ç°ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œæˆ‘æƒ³æä¸€ä¸‹è¿™ä¸ª API çš„å®ç°ã€‚ä½ å¯èƒ½ä¼šè®¤ä¸ºå®ç°è¿™ä¸ª API åº”è¯¥å¾ˆç®€å•ï¼Œä½†åœ¨ GC é¢†åŸŸï¼Œäº‹æƒ…å¾ˆå°‘æ˜¯ç®€å•çš„ ğŸ˜…ã€‚å½“ä½ è°ƒç”¨è¿™ä¸ª API æ—¶ï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ª `GCMemoryInfo` ç±»å‹çš„å®ä¾‹ï¼Œå…¶ä¸­çš„æ‰€æœ‰å­—æ®µéƒ½å±äºæœ€åä¸€ä¸ªå®Œæˆçš„ GCï¼Œæˆ–è€…å±äºä½ æŒ‡å®šç±»å‹çš„æœ€åä¸€ä¸ªå®Œæˆçš„ GCã€‚ç»ä¸ä¼šå‡ºç°æŸä¸ªå­—æ®µå±äºä¸€ä¸ª GC è€Œå¦ä¸€ä¸ªå­—æ®µå±äºå¦ä¸€ä¸ª GC çš„æƒ…å†µã€‚å¯¹äºé˜»å¡ GC æ¥è¯´ï¼Œè¿™æ˜¯å¾ˆå®¹æ˜“å®ç°çš„ï¼Œå› ä¸ºåœ¨é˜»å¡ GC æœŸé—´ç”¨æˆ·ä»£ç ä¸ä¼šè¿è¡Œã€‚åœ¨é˜»å¡ GC ç»“æŸæ—¶ï¼Œæˆ‘ä»¬ä¼šå¡«å……æ‰€æœ‰å­—æ®µï¼Œç„¶åæ¢å¤ç”¨æˆ·ä»£ç ï¼Œè¿™æ ·å¯ä»¥è½»æ¾ä¿è¯æ‰€æœ‰å­—æ®µéƒ½å±äºåŒä¸€ä¸ª GCã€‚ä½†å¯¹äºåå° GCï¼ˆBGCï¼‰ï¼Œæƒ…å†µåˆ™å¤æ‚å¾—å¤šã€‚

æˆ‘çš„åšæ³•æ˜¯ç»´æŠ¤ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…ƒç´ çš„ BGC ä¿¡æ¯æ•°ç»„ï¼Œå½“ä¸€ä¸ª BGC å¼€å§‹æ—¶ï¼Œç´¢å¼•ä¼šåœ¨ `!index` ä¹‹é—´åˆ‡æ¢ã€‚è¿™ä¸€æ“ä½œæ˜¯åœ¨ç”¨æˆ·çº¿ç¨‹è¢«æŒ‚èµ·æ—¶å®Œæˆçš„ï¼Œå› æ­¤ä¸å­˜åœ¨åŒæ­¥é—®é¢˜ã€‚è¿™å°±æ˜¯ BGC è®°å½•å…¶ä¿¡æ¯çš„ç´¢å¼•ã€‚å¦‚æœç”¨æˆ·ä»£ç åœ¨ BGC è¿›è¡Œä¸­è°ƒç”¨ API è¯·æ±‚æœ€åä¸€ä¸ª BGC çš„ä¿¡æ¯ï¼Œå®ƒä¼šè¿”å›å¦ä¸€ä¸ªç´¢å¼•ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“é‚£ä¸ªç´¢å¼•å¯¹åº”çš„æ˜¯æœ€åä¸€ä¸ªå®Œæˆçš„ BGCï¼ˆå¦‚æœå½“å‰ BGC æ˜¯ç¬¬ä¸€ä¸ª BGCï¼Œåˆ™è¿”å›å…¨é›¶ï¼‰ã€‚å¦‚æœæ²¡æœ‰ BGC æ­£åœ¨è¿›è¡Œï¼Œåˆ™è¿”å›å½“å‰ç´¢å¼•æŒ‡å‘çš„å†…å®¹ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“è¿™æ„å‘³ç€è¯¥ BGC å·²å®Œæˆä¸”æ˜¯æœ€åä¸€ä¸ª BGCã€‚

å¦ä¸€ä¸ªç¨å¾®æ£˜æ‰‹çš„åœ°æ–¹æ˜¯ BCL å’Œè¿è¡Œæ—¶ä¹‹é—´çš„äº¤äº’ï¼ˆæˆ‘çŸ¥é“ç°åœ¨ BCL ä¹Ÿåœ¨è¿è¡Œæ—¶ä»“åº“ä¸­ï¼›æˆ‘è¿˜æ˜¯ä¹ æƒ¯ç”¨â€œè¿è¡Œæ—¶â€æ¥æŒ‡ä»£æ ¸å¿ƒéƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯ `coreclr.dll` ä¸­çš„å†…å®¹ï¼‰ã€‚æˆ‘ä¸»è¦å¤„ç†è¿è¡Œæ—¶ä¸­çš„åŸç”Ÿä»£ç ï¼Œå¾ˆå°‘æ¶‰è¶³ BCLï¼Œå› ä¸º GC çš„å…¬å…±æ¥å£éå¸¸å°ã€‚é€šå¸¸ GC API çš„ BCL éƒ¨åˆ†éƒ½å¾ˆç®€å•ï¼Œä½†è¿™æ¬¡æ˜¯ä¸ªä¾‹å¤–ã€‚å¦‚æœä½ æŸ¥çœ‹ BCL è°ƒç”¨è¿è¡Œæ—¶çš„ä»£ç ï¼Œé€šå¸¸å®ƒä»¬ä¼ é€’çš„å‚æ•°éƒ½éå¸¸ç®€å•ï¼Œè¿™æ„å‘³ç€å®ƒä»¬åœ¨æ‰˜ç®¡ä»£ç å’ŒåŸç”Ÿä»£ç ä¹‹é—´ä¼ é€’èµ·æ¥å¾ˆå®¹æ˜“ã€‚ä½†è¿™ä¸ª API ä¸åŒâ€”â€”å®ƒä¼ é€’äº†ä¸€ä¸ªç›¸å½“å¤æ‚çš„ç»“æ„ï¼ŒåŒ…å«æ•°ç»„å­—æ®µå’Œéæ•°ç»„å­—æ®µã€‚ä¸€å¼€å§‹æˆ‘åœ¨åŸç”Ÿä»£ç ä¾§åšäº†ä¸€äº›å¤æ‚çš„äº‹æƒ…æ¥å¡«å……æ•°ç»„ï¼Œå› ä¸ºæˆ‘å¯¹æ‰˜ç®¡ä»£ç ä¸å¤ªç†Ÿæ‚‰ï¼Œè€Œä¸”æˆ‘å¯¹è¿™ç§å®ç°æ–¹å¼å¹¶ä¸æ»¡æ„ã€‚äºæ˜¯æˆ‘å¯»æ±‚äº† Jan çš„å¸®åŠ©ï¼Œä»–æ‰¾åˆ°äº†ä¸€ç§æ›´ä¼˜é›…çš„æ–¹å¼æ¥å®ç°æˆ‘æƒ³è¦çš„åŠŸèƒ½ï¼Œæ‰€ä»¥æˆ‘é‡‡ç”¨äº†ä»–çš„æ–¹æ¡ˆã€‚è¿™ä¸ªå®ç°åˆ†å¸ƒåœ¨æ‰˜ç®¡ä»£ç ä¾§çš„ `GCMemoryInfo.cs` å’Œ `GC.cs` æ–‡ä»¶ä»¥åŠåŸç”Ÿä»£ç ä¾§çš„ `comutilnative.cpp` æ–‡ä»¶ä¸­ã€‚æˆ‘æƒ³è±¡åªæœ‰æå°‘æ•°äººéœ€è¦è¿™æ ·åšï¼Œä½†å¦‚æœéœ€è¦çš„è¯ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„ç¤ºä¾‹ã€‚

`GCMemoryInfo` ç»“æ„ä½“ä¸­çš„å¤§å¤šæ•°å±æ€§éƒ½å¾ˆç›´è§‚ã€‚å”¯ä¸€å¯èƒ½å¼•èµ·æ··æ·†çš„æ˜¯ `Index`ã€‚åœ¨ä»»ä½• GC å‘ç”Ÿä¹‹å‰ï¼Œå¦‚æœä½ è°ƒç”¨è¿™ä¸ª APIï¼Œå®ƒä¼šè¿”å› `Index = 0`ã€‚ç¬¬ä¸€ä¸ª GC çš„ç´¢å¼•å°†æ˜¯ 1ï¼Œç¬¬äºŒä¸ªæ˜¯ 2ï¼Œä¾æ­¤ç±»æ¨ã€‚ä½ è¿˜å¯ä»¥å°†è¿™ä¸ªæ•°å­—ä¸ `GC.CollectionCount` è¿”å›çš„ç»“æœè¿›è¡Œå…³è”ï¼Œåè€…æˆæœ¬æ›´ä½ï¼Œå› ä¸ºæˆ‘ä»¬åªéœ€è¦è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œè€Œ `GetGCMemoryInfo` éœ€è¦å¡«å……è®¸å¤šå­—æ®µã€‚å¦‚æœç¬¬ä¸€ä¸ª GC æ˜¯ gen0 GCï¼Œé‚£ä¹ˆ `GC.CollectionCount(0)` å°†è¿”å› 1ï¼Œè¿™ä¸è°ƒç”¨ `GetGCMemoryInfo()` æˆ– `GetGCMemoryInfo(GCKind.Ephemeral)` è¿”å›çš„ `GCMemoryInfo.Index` ç›¸åŒã€‚å½“ç„¶ï¼Œç”±äºæˆ‘ä»¬éƒ½æ˜¯åœ¨æ‰˜ç®¡ä»£ç ä¸­æ“ä½œï¼Œæ‰€ä»¥åœ¨è°ƒç”¨ `CollectionCount` å’Œ `GetGCMemoryInfo` ä¹‹é—´å¯èƒ½ä¼šå‘ç”Ÿ GCï¼Œå› ä¸ºå…¶ä»–çº¿ç¨‹å¯èƒ½è§¦å‘äº† GC æˆ–ç³»ç»Ÿå¤„äºå†…å­˜å‹åŠ›ä¸‹ï¼Œä½†å®é™…ä¸Šè¿™ç§æƒ…å†µå‘ç”Ÿçš„æ¦‚ç‡å¾ˆå°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`CollectionCount` çš„ä¸€ä¸ªç‰¹æ€§æ˜¯ï¼šå½“æˆ‘ä»¬å¢åŠ æ›´é«˜ä»£åˆ«çš„æ”¶é›†è®¡æ•°æ—¶ï¼Œè¾ƒä½ä»£åˆ«çš„è®¡æ•°ä¹Ÿä¼šéšä¹‹å¢åŠ ã€‚å› æ­¤ï¼Œå¦‚æœä¸€å¼€å§‹å°±å‘ç”Ÿäº† gen1 GCï¼Œ`CollectionCount(0)` å’Œ `CollectionCount(1)` éƒ½å°†è¿”å› 1ã€‚

---

### ä½ èƒ½ç”¨è¿™äº›ä¿¡æ¯åšä»€ä¹ˆï¼Ÿ

`GCMemoryInfo` æä¾›äº†å¤§é‡å…³äº GC çš„ä¿¡æ¯ï¼Œä¾‹å¦‚ä»£åˆ«ã€æ˜¯å¦è¿›è¡Œäº†å‹ç¼©ã€æ˜¯å¦ä¸ºå¹¶å‘ GCã€è§‚å¯Ÿåˆ°çš„å›ºå®šå¯¹è±¡æ•°é‡ã€æš‚åœæ—¶é•¿ç­‰ã€‚åŸºæœ¬ä¸Šå¯ä»¥å°†å…¶è§†ä¸ºä» GC ETW äº‹ä»¶ä¸­è·å–çš„è¯¦ç»†ä¿¡æ¯çš„ç»„åˆã€‚ç”±äºå¼€å‘è€…æœ‰å¤šç§æ–¹å¼è¿›è¡Œç›‘æ§å’Œè¯Šæ–­ï¼Œå› æ­¤å¦‚æœä½ éœ€è¦è¿›è¡Œè¿›ç¨‹å†…ç›‘æ§å¹¶å¸Œæœ›è·å– GC ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä½ å·²ç»æœ‰ä¸€ä¸ªæ‰§è¡Œç›‘æ§çš„çº¿ç¨‹ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨æ­¤ API åŠ å¼ºå†…å­˜ç›‘æ§ï¼‰ï¼Œè¿™ä¸ª API è®©è¿™ä¸€åˆ‡å˜å¾—æ›´åŠ å®¹æ˜“ã€‚æˆ‘å¯ä»¥æƒ³åˆ°è®¸å¤šåˆ©ç”¨è¿™äº›ä¿¡æ¯çš„æ–¹æ³•ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›ä¾‹å­ï¼š

1. **ä¸ºä»€ä¹ˆæˆ‘çš„è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡æ¯” GC å †å¤§å°é«˜å¾—å¤šï¼Ÿ**  
   å¾ˆå¤šäººé—®è¿‡è¿™ä¸ªé—®é¢˜ã€‚äº‹å®è¯æ˜ï¼Œä»–ä»¬åªæ˜¯æ²¡æœ‰æµ‹é‡å³°å€¼å¤§å°ã€‚ä»–ä»¬è¦ä¹ˆåœ¨ GC åç«‹å³æµ‹é‡ï¼ˆè¿™æ˜¯æœ€å°çš„å¤§å°ï¼‰ï¼Œè¦ä¹ˆåœ¨éšæœºæ—¶åˆ»æµ‹é‡ï¼ˆè¿™å¯èƒ½æ˜¯åˆšåˆšå®Œæˆ GC åçš„å¤§å°ï¼Œæ¥è¿‘æœ€å°å€¼ï¼‰ã€‚è¿™åœ¨ mem-doc çš„â€œå¦‚ä½•æ­£ç¡®æŸ¥çœ‹ GC å †å¤§å°â€éƒ¨åˆ†ä¸­æœ‰è§£é‡Šã€‚å°½ç®¡ ETW æä¾›äº†æœ€ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä½†æˆ‘çœ‹åˆ°æœ‰äº›äººé”™è¯¯è§£è¯»äº† ETW äº‹ä»¶ã€‚æœ€è¿‘ï¼Œä¸€ä½å®¢æˆ·å‘Šè¯‰æˆ‘ï¼Œä»–ä»¬è®¤ä¸ºè®¾ç½®çš„ç¡¬é™åˆ¶ä¸èµ·ä½œç”¨ï¼Œå› ä¸ºå³ä½¿å¢åŠ äº†ç¡¬é™åˆ¶ï¼ŒGC å †ä»ç„¶ä¿æŒå¾ˆå°ã€‚è¿™æ˜¯å› ä¸ºä»–ä»¬åœ¨æŸ¥çœ‹ `GCHeapStats` äº‹ä»¶çš„å­—æ®µï¼Œè¿™äº›å­—æ®µæŠ¥å‘Šçš„æ˜¯â€œGC åâ€çš„å€¼ã€‚è¯šç„¶ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°è®°å½•è¿™äº›äº‹ä»¶ã€‚ä½†æˆ‘è®¤ä¸º `GetGCMemoryInfo` API æ˜ç¡®è¯´æ˜äº†ä½ è·å¾—çš„å†…å®¹â€”â€”`GCGenerationInfo` æ˜ç¡®æŒ‡å‡º `SizeBeforeBytes` æ˜¯è¿›å…¥ GC æ—¶çš„å¤§å°ï¼Œè¡¨ç¤ºå³°å€¼å¤§å°ã€‚

```csharp
public readonly struct GCGenerationInfo
{
    /// <summary>è¿›å…¥æ”¶é›†æ—¶çš„å­—èŠ‚å¤§å°ã€‚</summary>
    public long SizeBeforeBytes { get; }
    
    /// <summary>è¿›å…¥æ”¶é›†æ—¶çš„ç¢ç‰‡åŒ–å­—èŠ‚æ•°ã€‚</summary>
    public long FragmentationBeforeBytes { get; }
    
    /// <summary>é€€å‡ºæ”¶é›†æ—¶çš„å­—èŠ‚å¤§å°ã€‚</summary>
    public long SizeAfterBytes { get; }
    
    /// <summary>é€€å‡ºæ”¶é›†æ—¶çš„ç¢ç‰‡åŒ–å­—èŠ‚æ•°ã€‚</summary>
    public long FragmentationAfterBytes { get; }
}
```

åŒæ ·çš„ä¿¡æ¯ä¹Ÿä½œä¸º `GCPerHeapHistoryGenData` çš„ä¸€éƒ¨åˆ†æä¾›åœ¨ TraceEvent ä¸­ï¼Œä½†æ›´åŠ è¯¦ç»†â€”â€”æˆ‘ä»¬å°†ç¢ç‰‡åŒ–åˆ†ä¸º `FreeListSpace` å’Œ `FreeObjSpace`ï¼Œåè€…æ˜¯æŒ‡å¤ªå°è€Œæ— æ³•è¿›å…¥ç©ºé—²åˆ—è¡¨çš„ç©ºé—²å¯¹è±¡ã€‚

2. **ä¸ºä»€ä¹ˆ GC ä¸ä½¿ç”¨è¿™äº›ç©ºé—²ç©ºé—´ï¼Ÿ**  
   è¿™åŒæ ·å—åˆ°æµ‹é‡æ—¶é—´çš„å½±å“ã€‚å¦‚æœä½ åœ¨ BGC åç«‹å³æµ‹é‡ï¼Œç”±äºå®ƒçš„ä»»åŠ¡æ˜¯æ„å»ºç©ºé—²ç©ºé—´ï¼Œä½ å¯èƒ½ä¼šçœ‹åˆ°å¤§é‡çš„ç©ºé—²ç©ºé—´å‡ºç°åœ¨ gen2 æˆ– LOH ä¸­ã€‚é€šè¿‡è¿™ä¸ª APIï¼Œä½ å¯ä»¥è·å– GC å‰åçš„ç¢ç‰‡åŒ–ä¿¡æ¯ï¼ˆå³æ€»çš„ç©ºé—²ç©ºé—´ï¼‰ï¼Œä»è€Œåˆ¤æ–­ GC æ˜¯å¦ä½¿ç”¨äº†è¿™äº›ç©ºé—²ç©ºé—´ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰å¤§é‡çš„é•¿ç”Ÿå‘½å‘¨æœŸå›ºå®šå¯¹è±¡åˆ†æ•£åœ¨ gen0ï¼ˆå› ä¸ºæˆ‘ä»¬é™ä½äº†å®ƒä»¬çš„ä»£åˆ«ï¼‰ï¼Œ`FragmentationAfterBytes` å¯èƒ½ä¼šå¾ˆå¤§ï¼Œå› ä¸ºå›ºå®šå¯¹è±¡ä¹‹é—´æœ‰å¾ˆå¤šç©ºé—²ç©ºé—´ã€‚ä½†ä½ åº”è¯¥çœ‹åˆ° `FragmentationBeforeBytes` æ›´å°ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»ä½¿ç”¨è¿™äº›ç©ºé—²ç©ºé—´æ¥æ»¡è¶³åˆ†é…è¯·æ±‚ã€‚

3. **ç›‘æ§ä¸é¢‘ç¹çš„ GC**  
   ä½ å¯ä»¥é€šè¿‡è°ƒç”¨æ­¤ API å¹¶æŒ‡å®š `GCKind.FullBlocking` æ¥éå¸¸ä¸é¢‘ç¹åœ°ç›‘æ§ï¼Œä»¥åˆ¤æ–­æ˜¯å¦å‘ç”Ÿäº†å®Œæ•´çš„é˜»å¡ GCã€‚å¦‚æœä½ å¸Œæœ›é¿å…è¿™ç±» GCï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½å¯¼è‡´éå¸¸é•¿çš„æš‚åœï¼Œè¿™ç§æ–¹æ³•éå¸¸æœ‰ç”¨ã€‚
A usage example for measuring the GC impact of your tail latency
Recently I helped a team to measure the GC impact of their tail latency which I thought would be very useful for other people who care about tail latency. In my mem-doc I talked about measuring the GC impact of tail latency and this team was interested to do that so I helped them to write the code that utilizes this updated API to achieve it. It's important to mention the context here â€“ this was used in their test scenarios where we know there are no full blocking GCs happening. So we only needed to check for ephemeral GCs and BGCs. I'll leave checking for full blocking GCs as an exercise to the readers ğŸ™‚

4) **"% time in GC" æ€§èƒ½è®¡æ•°å™¨çš„é—®é¢˜**  
"% time in GC" æ€§èƒ½è®¡æ•°å™¨ä»…é€‚ç”¨äºæœ€åä¸€ä¸ª GCï¼ˆå¦‚æœå‘ç”Ÿäº†åå° GCï¼Œè¿™ä¸ªå€¼å¯èƒ½å¹¶ä¸å‡†ç¡®ï¼‰ã€‚å¯¹äºé•¿æœŸç›‘æ§è€Œè¨€ï¼Œäº†è§£åˆ°ç›®å‰ä¸ºæ­¢ GC çš„æš‚åœæ—¶é—´ç™¾åˆ†æ¯”æ›´ä¸ºæœ‰ç”¨ã€‚å› æ­¤ï¼ŒAPI æä¾›çš„ `PauseTimePercentage` å°±æ˜¯ä¸ºæ­¤è®¾è®¡çš„ï¼Œéå¸¸é€‚åˆç”¨äºé•¿æœŸç›‘æ§ã€‚å¦‚æœä½ æƒ³è¦çŸ¥é“æ¯ä¸ªå•ç‹¬ GC çš„æš‚åœæ—¶é•¿ï¼Œå¯ä»¥æŸ¥çœ‹ `PauseDurations` å±æ€§ï¼Œå®ƒæä¾›äº†ä¸¤ä¸ªæ—¶é•¿â€”â€”å¯¹äºé˜»å¡å‹ GC æ¥è¯´ï¼Œç”±äºå®ƒä»¬åªæœ‰ä¸€ä¸ªæš‚åœé˜¶æ®µï¼Œæ‰€ä»¥åªä½¿ç”¨ç¬¬ä¸€ä¸ªæ—¶é•¿ã€‚è€Œå¯¹äºåå° GCï¼ˆBGCï¼‰ï¼Œæœ‰ä¸¤ä¸ªæ—¶é•¿ï¼Œå› ä¸ºæ¯æ¬¡ BGC ä¼šæš‚åœä¸¤æ¬¡ï¼šä¸€æ¬¡æ˜¯åˆå§‹æš‚åœï¼Œå¦ä¸€æ¬¡æ˜¯åœ¨æ ‡è®°é˜¶æ®µç»“æŸæ—¶ï¼ˆåœ¨ mem-doc çš„â€œGC äº‹ä»¶åºåˆ—â€éƒ¨åˆ†ä¸­æœ‰è¯¦ç»†æè¿°ï¼‰ã€‚ä½ å¯ä»¥åˆ†åˆ«è·å–è¿™äº›æš‚åœæ—¶é•¿ã€‚å®é™…ä¸Šï¼Œè¿™æ¯” TraceEvent æä¾›çš„ä¿¡æ¯æ›´è¯¦ç»†ï¼ŒTraceEvent å°†è¿™ä¸¤ä¸ªæš‚åœåˆå¹¶ä¸ºä¸€ä¸ªï¼Œå¹¶æŠ¥å‘Šæ€»æ—¶é•¿ï¼Œä½ å¯ä»¥åœ¨ PerfView çš„ GCStats è§†å›¾ä¸­çš„ "Pause MSec" åˆ—ä¸­çœ‹åˆ°è¿™ä¸€ç»“æœã€‚

---

5) **ä»£åˆ«å¯¹ GC çš„é‡è¦æ€§**  
æˆ‘åœ¨ mem-doc ä¸­è¯¦ç»†è®¨è®ºäº†äº†è§£ GC çš„ä»£åˆ«ç‰¹æ€§çš„é‡è¦æ€§ã€‚ä¸å¹¸çš„æ˜¯ï¼Œå¾ˆå°‘æœ‰å·¥å…·çœŸæ­£æš´éœ²äº†è¿™ä¸€ç‰¹æ€§ã€‚ç”šè‡³ä¸€äº›ç»éªŒä¸°å¯Œçš„æ€§èƒ½å·¥ç¨‹å¸ˆå¯¹æ­¤ä¹Ÿå®Œå…¨æ²¡æœ‰æ„è¯†ã€‚è¿™ä¸ª API æä¾›äº†æ¯æ¬¡ GC çš„ `PromotedBytes`ï¼Œä½ å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°çŸ­æš‚ä»£ GC å’Œå®Œæ•´ GC ä¹‹é—´çš„æå‡å­—èŠ‚æ•°å·®å¼‚ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å°†çŸ­æš‚ä»£ GC çš„ `PauseDurations[0]` ä¸å…¶ `PromotedBytes` å…³è”èµ·æ¥ã€‚å¦‚æœä½ å‘ç°å®ƒä»¬ä¹‹é—´å®Œå…¨æ²¡æœ‰å…³è”ï¼Œæ¯”å¦‚å°½ç®¡æå‡çš„å­—èŠ‚æ•°ä¿æŒç¨³å®šï¼Œä½†æš‚åœæ—¶é•¿å´æœ‰å¾ˆå¤§æ³¢åŠ¨ï¼Œé‚£ä¹ˆå¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Server GCï¼Œå¯èƒ½æ˜¯é‡åˆ°äº† CPU è¢«æŠ¢å çš„é—®é¢˜ï¼ˆstolen CPU problemï¼‰ã€‚

è¿™ç§æƒ…å†µä¸‹ï¼ŒCPU æ—¶é—´è¢«å…¶ä»–ä»»åŠ¡å ç”¨ï¼Œå¯¼è‡´ GC çº¿ç¨‹æ— æ³•è·å¾—è¶³å¤Ÿçš„ CPU æ—¶é—´æ¥å®Œæˆå…¶å·¥ä½œï¼Œä»è€Œå¢åŠ äº†æš‚åœæ—¶é—´ã€‚é€šè¿‡ç»“åˆåˆ†æ `PauseDurations` å’Œ `PromotedBytes`ï¼Œä½ å¯ä»¥æ›´å¥½åœ°è¯Šæ–­å’Œç†è§£ GC çš„è¡Œä¸ºï¼Œå°¤å…¶æ˜¯å½“ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜æˆ–å­˜åœ¨èµ„æºäº‰ç”¨æ—¶ã€‚

// The requests here are only requests of interest to our analysis, ie the ones that 
// took >=rangeStart and < rangeEnd milliseconds.
ulong global_totalReqsAffectedByGC = 0;
ulong global_totalReqs = 0;
ulong global_totalReqsAffectedByMultipleGCs = 0;
ulong global_unfortunateReqs = 0;
ulong global_totalReqsGCDurationMSec = 0;
ulong global_totalReqsDurationMSec = 0;

// in each request -
var startGollectionCount = GC.CollectionCount(0);
var startGen2CollectionCount = GC.CollectionCount(2);
stopwatch.Start();

// user request happens here
myRequest();

stopwatch.Stop();
ulong reqDurationMSec = (ulong)stopWatch.ElapsedMilliseconds;

int endCollectionCount = GC.CollectionCount(0);

// This is a request of interest.
if ((time >= rangeStart) && (time < rangeEnd))
{
    Interlocked.Add(ref global_totalReqsDurationMSec, reqDurationMSec);
    var endCollectionCount = GC.CollectionCount(0);
    var endGen2CollectionCount = GC.CollectionCount(2);

    GCMemoryInfo lastEphemeralGCInfo = GC.GetGCMemoryInfo(GCKind.Ephemeral);

    if (endCollectionCount > startGollectionCount)
    {
        Interlocked.Increment(ref global_totalReqsAffectedByGC);

        // For global_totalReqsAffectedByMultipleGCs we only count if there were multiple ephemeral GCs
        if (((endCollectionCount - startGCCount) > 1) && (endGen2CollectionCount == startGen2GCCount))
        {
            Interlocked.Increment(ref global_totalReqsAffectedByMultipleGCs);
        }
        // There could be an ephemeral GC happened inbetween getting endCollectionCount and 
        // lastEphemeralGCInfo. This would be very rare but can happen. So we just log it as
        // an unfortunate outlier case.
        if (lastEphemeralGCInfo.Index != endCollectionCount)
        {
            Interlocked.Increment(ref global_unfortunateReqs);
        }
        else
        {
            // Now we can calculate the GC impact on this request.
            // Of course you can also preserve enough accurancy on the GC pause duration by multiplying it with 10
            // so you don't lose the .x ms part. Just need to compensate for that when you do the impact calcuation.
            Interlocked.Add(ref global_totalReqsGCDurationMSec, (ulong)lastEphemeralGCInfo.PauseDurations[0].TotalMilliseconds);

            // You could also record the GC index because multiple requests could be affected by the same GC so you
            // know how many total unique GCs affected these requests.
        }
    }
}
view rawgcimpact.cs hosted with â¤ by GitHub
It's worth explaining line#37. We could have this case â€“

request begin: gc count is 1 (and gen2 count is 0)
now a BGC happens which increases the gc count to 2; and before we restart the user threads we choose to do a gen0 or gen1 GC which would increase gc count to 3. (we increase the gc count at the beginning of each GC)
user threads are now restarted
request end: gc count is 3 (and gen2 count is 1)
So at request end we would have observed multiple GCs, but most of the pause time would be from the gen0/1 GC. We could detect this by getting the gen2 count at the beginning as well as gen0 count (it would be better if we had an API that gets gen0/1/BGC/full blocking GC counts all at once instead of having to call multiple of them; I'll definitely think about adding that API).

And this would be the kind of output you'd get â€“

(global_totalReqsAffectedByGC / global_totalReqs) * 100 --> % requests affected by GC

(global_totalReqsGCDurationMSec / global_totalReqsDurationMSec) * 100 --> GC impact in these requests.

global_totalReqsAffectedByMultipleGCs, global_unfortunateReqs --> just to make sure those are indeed rare.

This is very useful because it tells you whether you should focus on finding out if other factors contribute to your tail latency if the GC impact is low. And if the GC impact is high then you know if you concentrated on improve the GC perf it would help reducing your tail latency. And you can give it different ranges to define which latency bucket you are concentrating on so you can know things like "GC seems to impact my Px request latency a lot but not much my Py latency so if my highest priority is to reduce Py latency I should spend time on something else" (where Px and Py is x and y percentile respectively). And this is the kind of things that I see folks mostly do guessing work on today so I definitely hope you take advantage of the new API!

### è¯·æ±‚å¼€å§‹ï¼šGC è®¡æ•°ä¸º 1ï¼ˆgen2 è®¡æ•°ä¸º 0ï¼‰
ç°åœ¨å‘ç”Ÿäº†ä¸€ä¸ªåå° GC (BGC)ï¼Œè¿™å°† GC è®¡æ•°å¢åŠ åˆ° 2ï¼›åœ¨æˆ‘ä»¬é‡æ–°å¯åŠ¨ç”¨æˆ·çº¿ç¨‹ä¹‹å‰ï¼Œæˆ‘ä»¬é€‰æ‹©è¿›è¡Œä¸€æ¬¡ gen0 æˆ– gen1 GCï¼Œè¿™ä¼šå°† GC è®¡æ•°è¿›ä¸€æ­¥å¢åŠ åˆ° 3ã€‚ï¼ˆæˆ‘ä»¬åœ¨æ¯æ¬¡ GC å¼€å§‹æ—¶éƒ½ä¼šå¢åŠ  GC è®¡æ•°ã€‚ï¼‰  
ç”¨æˆ·çº¿ç¨‹ç°åœ¨é‡æ–°å¯åŠ¨ã€‚  
**è¯·æ±‚ç»“æŸï¼šGC è®¡æ•°ä¸º 3ï¼ˆgen2 è®¡æ•°ä¸º 1ï¼‰ã€‚**

å› æ­¤ï¼Œåœ¨è¯·æ±‚ç»“æŸæ—¶ï¼Œæˆ‘ä»¬ä¼šè§‚å¯Ÿåˆ°å¤šä¸ª GCï¼Œä½†å¤§éƒ¨åˆ†æš‚åœæ—¶é—´å®é™…ä¸Šæ¥è‡ªäº gen0/1 GCã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨å¼€å§‹æ—¶è·å– gen2 è®¡æ•°ä»¥åŠ gen0 è®¡æ•°æ¥æ£€æµ‹è¿™ä¸€ç‚¹ã€‚ï¼ˆå¦‚æœæœ‰ä¸€ä¸ª API èƒ½ä¸€æ¬¡æ€§è·å– gen0ã€gen1ã€BGC å’Œå®Œæ•´é˜»å¡ GC çš„è®¡æ•°ï¼Œè€Œä¸æ˜¯å¤šæ¬¡è°ƒç”¨ä¸åŒçš„æ–¹æ³•ï¼Œé‚£å°±æ›´å¥½äº†ï¼›æˆ‘ä¸€å®šä¼šè€ƒè™‘æ·»åŠ è¿™æ ·ä¸€ä¸ª APIã€‚ï¼‰

---

### è¿™æ˜¯ä½ å¯èƒ½ä¼šå¾—åˆ°çš„è¾“å‡ºï¼š

- **(global_totalReqsAffectedByGC / global_totalReqs) * 100** â†’ å— GC å½±å“çš„è¯·æ±‚æ•°ç™¾åˆ†æ¯”ã€‚
- **(global_totalReqsGCDurationMSec / global_totalReqsDurationMSec) * 100** â†’ GC å¯¹è¿™äº›è¯·æ±‚çš„å½±å“ç™¾åˆ†æ¯”ã€‚
- **global_totalReqsAffectedByMultipleGCs, global_unfortunateReqs** â†’ ä»…ä¸ºäº†ç¡®ä¿è¿™äº›æƒ…å†µç¡®å®å¾ˆå°‘å‘ç”Ÿã€‚

è¿™éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥å‘Šè¯‰ä½ æ˜¯å¦åº”è¯¥ä¸“æ³¨äºæŸ¥æ‰¾å…¶ä»–å› ç´ å¯¹å°¾éƒ¨å»¶è¿Ÿçš„å½±å“ï¼ˆå¦‚æœ GC çš„å½±å“è¾ƒä½çš„è¯ï¼‰ã€‚è€Œå¦‚æœ GC çš„å½±å“è¾ƒé«˜ï¼Œåˆ™ä½ å¯ä»¥çŸ¥é“é›†ä¸­ç²¾åŠ›ä¼˜åŒ– GC æ€§èƒ½æ˜¯å¦ä¼šå¸®åŠ©é™ä½å°¾éƒ¨å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œä½ å¯ä»¥å®šä¹‰ä¸åŒçš„å»¶è¿ŸèŒƒå›´ï¼Œä»¥ç¡®å®šä½ å…³æ³¨çš„æ˜¯å“ªä¸ªå»¶è¿ŸåŒºé—´ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å¾—å‡ºè¿™æ ·çš„ç»“è®ºï¼šâ€œGC å¯¹æˆ‘çš„ Px è¯·æ±‚å»¶è¿Ÿæœ‰å¾ˆå¤§å½±å“ï¼Œä½†å¯¹ Py å»¶è¿Ÿå½±å“ä¸å¤§ï¼Œå› æ­¤å¦‚æœæˆ‘çš„æœ€é«˜ä¼˜å…ˆçº§æ˜¯å‡å°‘ Py å»¶è¿Ÿï¼Œæˆ‘åº”è¯¥æŠŠæ—¶é—´èŠ±åœ¨å…¶ä»–äº‹æƒ…ä¸Šã€‚â€ï¼ˆå…¶ä¸­ Px å’Œ Py åˆ†åˆ«è¡¨ç¤º x å’Œ y ç™¾åˆ†ä½çš„å»¶è¿Ÿã€‚ï¼‰

ä»Šå¤©ï¼Œæˆ‘çœ‹åˆ°å¾ˆå¤šäººåœ¨è¿™æ–¹é¢ä¸»è¦ä¾èµ–çŒœæµ‹å·¥ä½œï¼Œæ‰€ä»¥æˆ‘å¼ºçƒˆå»ºè®®ä½ å……åˆ†åˆ©ç”¨è¿™ä¸ªæ–°çš„ APIï¼